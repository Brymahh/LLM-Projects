{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1773990-6fc8-4216-b9a7-a78527d8ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d056655-8e9c-46f5-9acd-6c3d78ab8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate client\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c00c0a-56c1-45fd-beab-2ad4a9777b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: send a prompt \n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{'role':'user', 'content':'what is elastic search'}]\n",
    "\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e2b33d-ceb8-4f89-8780-6f4a5766a916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9hGFTbUYS43m5opP44FQztPzBrWDf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Elasticsearch is a distributed, RESTful search and analytics engine designed for horizontal scalability, reliability, and real-time search capabilities. It is built on top of the Apache Lucene search library and provides a simple and powerful API to store, index, search, and analyze large volumes of data in real-time. Elasticsearch is commonly used for log aggregation, full-text search, and analytics in a variety of applications and industries.', role='assistant', function_call=None, tool_calls=None))], created=1720097591, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=84, prompt_tokens=11, total_tokens=95))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b425c42-68bd-4a31-a13b-b45d95405c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elasticsearch is a distributed, RESTful search and analytics engine designed for horizontal scalability, reliability, and real-time search capabilities. It is built on top of the Apache Lucene search library and provides a simple and powerful API to store, index, search, and analyze large volumes of data in real-time. Elasticsearch is commonly used for log aggregation, full-text search, and analytics in a variety of applications and industries.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac200b7-c0ed-43cd-bbdf-24875650c1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c2b9e-2dec-4902-abdc-0acca7251a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e150c8-b98f-47ee-be55-bb82b4d9a7ed",
   "metadata": {},
   "source": [
    "### Preparing the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e742920f-9b18-4f90-9547-b5a78b126928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-03 12:54:55--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-07-03 12:54:55 (15.3 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee5717f-19cb-4a3c-87e9-21f63ed42900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "390b03ca-10ce-4c4d-a938-a6225cf6013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-03 13:06:14--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 658332 (643K) [text/plain]\n",
      "Saving to: ‘documents.json’\n",
      "\n",
      "documents.json      100%[===================>] 642.90K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-07-03 13:06:14 (38.5 MB/s) - ‘documents.json’ saved [658332/658332]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1997e21c-027b-40a6-a031-5159727a059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60914315-6f57-43cc-a830-e80e8786618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod the json documents\n",
    "\n",
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461aef1d-58c7-4e3e-9bb5-1c54cec3564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting json file to a list\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37ba2fe-3f24-4727-a843-2b8567a3930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098eaf21-10a0-4ebf-91c6-5dee5f4fc696",
   "metadata": {},
   "source": [
    "## Interacting with the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f143e7-4d69-411f-a83d-f9385b05981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Index and specify the search elements\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields = ['question', 'text', 'section'],\n",
    "    keyword_fields= ['course'] #condition to restrict documents to the course: data-engineering-zoomcamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c8e4a4-f71a-45ae-bc62-cd961477844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'elasticsearch has quit unexpectedly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38e0e7e4-f8ac-4d0b-8738-eed28235d8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x79980865c430>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0815289b-ce88-4798-8fa1-6fe6059312ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "qu = 'can I still enroll if the course starts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "648ddedb-3dc8-4890-bf3c-563960b9ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we think one of the text fields is more important than the other, we use boost\n",
    "boost = {\"question\": 3.0, \"section\": 0.5}\n",
    "\n",
    "\n",
    "results = index.search(\n",
    "    query = qu,\n",
    "    filter_dict = {\"course\":\"data-engineering-zoomcamp\"},\n",
    "    boost_dict = boost,\n",
    "    num_results = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "698bcc8e-007f-4da2-81b8-32ff6d2872cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1d39d-c5cf-4fd7-8a60-8cba25cd3bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2a742ff-7682-4309-90a5-c809cd397ca6",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11a1342c-a616-4bf2-80d0-f688bf16764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qu = 'can I still enroll if the course starts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87a97803-fbe4-4f1f-a61f-d260d22b3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic response from LLM\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\":\"user\", \"content\":qu}]\n",
    "\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc3731db-3d35-46a9-8ee7-336ccd75e8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It ultimately depends on the policies and procedures of the specific institution or course provider. Some may allow late enrollment for a course that has already started, while others may not. It is best to contact the institution or course provider directly to inquire about their enrollment policies and see if it is possible to still enroll in the course.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4f4ff86-72a6-4481-add6-ee4be5aa2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a prompt to guide the LLMs response\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ Database. \n",
    "use only the facts from the CONTEXT when answering the QUESTION.\n",
    "if the CONTEXT does not contain the answer, output NONE.\n",
    "\n",
    "QUESTION : {question}\n",
    "\n",
    "CONTEXT : {context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65c49e1e-420d-496f-a975-6f1e4a89a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "context =\"\"\n",
    "\n",
    "for doc in results:\n",
    "    context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e5944d5-168b-45ce-ad7e-f0f5f2f3cec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section: General course-related questions\n",
      "question: Course - What can I do before the course starts?\n",
      "answer: You can start by installing and setting up all the dependencies and requirements:\n",
      "Google cloud account\n",
      "Google Cloud SDK\n",
      "Python 3 (installed with Anaconda)\n",
      "Terraform\n",
      "Git\n",
      "Look over the prerequisites and syllabus to see if you are comfortable with these subjects.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I get support if I take the course in the self-paced mode?\n",
      "answer: Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\n",
      "You can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8b2b9cf-4393-477d-88de-dcbf92bf9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question = qu, context = context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a48fbc4-467b-4fe8-8c1a-a827f2f6a6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ Database. \n",
      "use only the facts from the CONTEXT when answering the QUESTION.\n",
      "if the CONTEXT does not contain the answer, output NONE.\n",
      "\n",
      "QUESTION : can I still enroll if the course starts\n",
      "\n",
      "CONTEXT : section: General course-related questions\n",
      "question: Course - What can I do before the course starts?\n",
      "answer: You can start by installing and setting up all the dependencies and requirements:\n",
      "Google cloud account\n",
      "Google Cloud SDK\n",
      "Python 3 (installed with Anaconda)\n",
      "Terraform\n",
      "Git\n",
      "Look over the prerequisites and syllabus to see if you are comfortable with these subjects.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I get support if I take the course in the self-paced mode?\n",
      "answer: Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\n",
      "You can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cba37154-9777-4195-bcb8-165052405584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, you can still join the course after the start date.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining Both GPT and The Search result\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\":\"user\", \"content\":prompt}]\n",
    "\n",
    ")\n",
    "   \n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41cb247-4c3f-45f5-b5d5-217a3c1a1f7c",
   "metadata": {},
   "source": [
    "# Cleaning up with a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "640729aa-9784-4670-a02b-597cc9765b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search the database\n",
    "\n",
    "def search(query):\n",
    "    boost = {\"question\": 3.0, \"section\": 0.5}\n",
    "\n",
    "\n",
    "    results = index.search(\n",
    "        query = query,\n",
    "        filter_dict = {\"course\":\"data-engineering-zoomcamp\"},\n",
    "        boost_dict = boost,\n",
    "        num_results = 10\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1c54e964-8660-4adb-918d-7f0d9d87275a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"It's up to you which platform and environment you use for the course.\\nGithub codespaces or GCP VM are just possible options, but you can do the entire course from your laptop.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Do we really have to use GitHub codespaces? I already have PostgreSQL & Docker installed.',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Instruction on how to store secrets that will be avialable in GitHub  Codespaces.\\nManaging your account-specific secrets for GitHub Codespaces - GitHub Docs',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': 'GitHub Codespaces - How to store secrets',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Choose the approach that aligns the most with your idea for the end project\\nOne of those should suffice. However, BigQuery, which is part of GCP, will be used, so learning that is probably a better option. Or you can set up a local environment for most of this course.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Do I need both GitHub Codespaces and GCP?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'GitHub Codespaces offers you computing Linux resources with many pre-installed tools (Docker, Docker Compose, Python).\\nYou can also open any GitHub repository in a GitHub Codespace.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Is GitHub codespaces an alternative to using cli/git bash to ingest the data and create a docker file?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\nYou might face some challenges, especially for Windows users. If you face cnd2\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\nUsing GitHub Codespaces\\nSetting up the environment on a cloudV Mcodespace\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': '~ Abhijit Chakraborty\\n`sdk list java`  to check for available java sdk versions.\\n`sdk install java 11.0.22-amzn`  as  java-11.0.22-amzn was available for my codespace.\\nclick on Y if prompted to change the default java version.\\nCheck for java version using `java -version `.\\nIf working fine great, else `sdk default java 11.0.22-amzn` or whatever version you have installed.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Installing Java 11 on codespaces',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, you can. Just remember to adapt all the information on the videos to AWS. Besides, the final capstone will be evaluated based on the task: Create a data pipeline! Develop a visualisation!\\nThe problem would be when you need help. You’d need to rely on  fellow coursemates who also use AWS (or have experience using it before), which might be in smaller numbers than those learning the course with GCP.\\nAlso see Is it possible to use x tool instead of the one tool you use?',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - I want to use AWS. May I do that?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Vic created three different datasets in the videos.. dbt_<name> was used for development and you used a production dataset for the production environment. What was the use for the staging dataset?\\nR: Staging, as the name suggests, is like an intermediate between the raw datasets and the fact and dim tables, which are the finished product, so to speak. You'll notice that the datasets in staging are materialised as views and not tables.\\nVic didn't use it for the project, you just need to create production and dbt_name + trips_data_all that you had already.\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': 'Why do we need the Staging dataset?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'CSV Files are very big in nyc data, so we instead of using Pandas/Python kernel , we can try Pyspark Kernel\\nDocumentation of Mage for using pyspark kernel: https://docs.mage.ai/integrations/spark-pyspark\\n?',\n",
       "  'section': 'Module 2: Workflow Orchestration',\n",
       "  'question': 'Since I was using slow laptop, and we have so big csv files, I used pyspark kernel in mage instead of python, How to do it?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('do we really have to use github codespaces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c0ddcce4-d71e-4784-8b38-8428c56917c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the prompt template\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ Database. Do not explicitly use the word CONTEXT in your response. \n",
    "    use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    if the CONTEXT does not contain the answer, output NONE.\n",
    "    \n",
    "    QUESTION : {question}\n",
    "    \n",
    "    CONTEXT : {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context =\"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question = query, context = context).strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5ea1290f-a63a-43ae-9d1a-16089b3dd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to link query with openai-api\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\":\"user\", \"content\":prompt}]\n",
    "    \n",
    "    )\n",
    "       \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ab91907-1a34-42e6-b92f-0c2eee392ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'how do I install anaconda'\n",
    "search_results = search(query)\n",
    "prompt = build_prompt(query, search_results)\n",
    "answer = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f226df67-8394-464d-a82e-b511e42cdf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To install Anaconda for this course, you can start by installing and setting up all the dependencies and requirements mentioned in the FAQ: Google cloud account, Google Cloud SDK, Python 3 (installed with Anaconda), Terraform, and Git.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "29ce5e29-5186-4bd1-83ec-f963d2fa97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = 'how do I install anaconda'\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "81a2627c-0e74-438d-9502-74f9c851c260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NONE'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('What are the prerequisites for this course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9e3c16f9-f43c-4493-be88-52d2f8c4856e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To install the necessary dependencies to run the code for the course, you should start by installing and setting up the following:\\n- Google cloud account\\n- Google Cloud SDK\\n- Python 3 (installed with Anaconda)\\n- Terraform\\n- Git\\n\\nMake sure to check the prerequisites and syllabus to ensure you are comfortable with these subjects.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('How do I install the necessary dependencies to run the code?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e35ae27-619d-46e1-b4be-585f9a24791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To install Anaconda for the course, you can start by installing and setting up all the dependencies and requirements as listed in the FAQ Database, which includes Python 3 installed with Anaconda.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "37d658b2-83ea-483b-ba28-80caab3cc7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The confirmation email for the course will be sent on the 15th Jan 2024 at 17h00, which is when the course will officially start with the first \"Office Hours\" live.'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('When can I expect to receive the confirmation email?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3c3f7-5c8c-4a34-968d-e3d1f4785aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f316f977-24b3-47c7-a175-6d464fe212ef",
   "metadata": {},
   "source": [
    "# Using Elastic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bab76f-0160-4320-80cb-e88637bcb1d4",
   "metadata": {},
   "source": [
    "#command line.\n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8a6d7135-b01f-4b9b-8633-cac2fc4f9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "98fcd648-5786-42b7-b8ae-39d3f09bae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "#es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99f310-da33-429f-bc4d-7927756e832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es.indices.create(index = index_name, body = index_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25a21b42-7ac2-4eeb-9c9c-b6b0c55b91e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "096edf9c-71c0-4d9a-b08b-d8aa4a9c382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:23<00:00, 40.98it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for doc in tqdm(documents):\n",
    "    es.index(index = index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7a7e3dd4-8d7d-4e49-bb6a-18ef548b97d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What are the prerequisites for this course'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5e4e54ed-2ec3-49ac-ae91-162b3740c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the query\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1511a0bb-33d2-4480-84c1-7244ca2e6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_es = es.search(index= index_name, body = search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "806acf1d-2332-4376-9d89-21aa03ac4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_docs = []\n",
    "\n",
    "for hit in response_es['hits']['hits']:\n",
    "    response_docs.append(hit['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d8a92e54-99c9-41f4-bbae-44e50ba111eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What are the prerequisites for this course?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'After you submit your homework it will be graded based on the amount of questions in a particular homework. You can see how many points you have right on the page of the homework up top. Additionally in the leaderboard you will find the sum of all points you’ve earned - points for Homeworks, FAQs and Learning in Public. If homework is clear, others work as follows: if you submit something to FAQ, you get one point, for each learning in a public link you get one point.\\n(https://datatalks-club.slack.com/archives/C01FABYF2RG/p1706846846359379?thread_ts=1706825019.546229&cid=C01FABYF2RG)',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework and Leaderboard - what is the system for points in the course management platform?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8fffd018-fbea-411c-bb48-a0041e42ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything in query\n",
    "\n",
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response_es = es.search(index= index_name, body = search_query)\n",
    "    \n",
    "    response_docs = []\n",
    "\n",
    "    for hit in response_es['hits']['hits']:\n",
    "        response_docs.append(hit['_source'])\n",
    "\n",
    "    return response_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "48127451-efd3-452f-b81b-7a1e33134b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Change TO Socket\\npgcli -h 127.0.0.1 -p 5432 -u root -d ny_taxi\\npgcli -h 127.0.0.1 -p 5432 -u root -d ny_taxi',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': 'PGCLI - connection failed: :1), port 5432 failed: could not receive data from server: Connection refused could not send SSL negotiation packet: Connection refused',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"If you’re using an Anaconda installation:\\nCd home/\\nConda install gcc\\nSource back to your RisingWave Venv - source .venv/bin/activate\\nPip install psycopg2-binary\\nPip install -r requirements.txt\\nFor some reason this worked - the Conda base doesn’t have the GCC installed - (GNU Compiler Collection) a compiler system that supports various programming languages. Without this the it fails to install pyproject.toml-based projects\\n“It's possible that in your specific environment, the gcc installation was required at the system level rather than within the virtual environment. This can happen if the build process for psycopg2 tries to access system-level dependencies during installation.\\nInstalling gcc in your main Python installation (Conda) would make it available system-wide, allowing any Python environment to access it when necessary for building packages.”\\ngcc stands for GNU Compiler Collection. It is a compiler system developed by the GNU Project that supports various programming languages, including C, C++, Objective-C, and Fortran.\\nGCC is widely used for compiling source code written in these languages into executable programs or libraries. It's a key tool in the software development process, particularly in the compilation stage where source code is translated into machine code that can be executed by a computer's processor.\\nIn addition to compiling source code, GCC also provides various optimization options, debugging support, and extensive documentation, making it a powerful and versatile tool for developers across different platforms and architectures.\\n—-----------------------------------------------------------------------------------\",\n",
       "  'section': 'Workshop 2 - RisingWave',\n",
       "  'question': 'Psycopg2 - `Could not build wheels for psycopg2, which is required to install pyproject.toml-based projects`',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'In case the script gets stuck on\\n%3|1709652240.100|FAIL|rdkafka#producer-2| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)gre\\nafter trying to load the trip data, check the logs of the message_queue container in docker. If it keeps restarting with Could not initialize seastar: std::runtime_error (insufficient physical memory: needed 4294967296 available 4067422208)  as the last message, then go to the docker-compose file in the docker folder of the project and change the ‘memory’ command for the message_queue service for some lower value.\\nSolution: lower the memory allocation of the service “message_queue” in your docker-compose file from 4GB. If you have the “insufficient physical memory” error message (try 3GB)\\nIssue: Running psql -f risingwave-sql/table/trip_data.sql after starting services with ‘default’ values using docker-compose up gives the error  “psql:risingwave-sql/table/trip_data.sql:61: ERROR:  syntax error at or near \".\" LINE 60:       properties.bootstrap.server=\\'message_queue:29092\\'”\\nSolution: Make sure you have run source commands.sh in each terminal window',\n",
       "  'section': 'Workshop 2 - RisingWave',\n",
       "  'question': 'Running stream-kafka script gets stuck on a loop with Connection Refused',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Check Docker Compose File:\\nEnsure that your docker-compose.yaml file is correctly configured with the necessary details for the \"control-center\" service. Check the service name, image name, ports, volumes, environment variables, and any other configurations required for the container to start.\\nOn Mac OSX 12.2.1 (Monterey) I could not start the kafka control center. I opened Docker Desktop and saw docker images still running from week 4, which I did not see when I typed “docker ps.” I deleted them in docker desktop and then had no problem starting up the kafka environment.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Could not start docker image “control-center” from the docker-compose.yaml file.',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'I found this error while executing the user defined function in Spark (crazy_stuff_udf). I am working on Windows and using conda. After following the setup instructions, I found that the PYSPARK_PYTHON environment variable was not set correctly, given that conda has different python paths for each environment.\\nSolution:\\npip install findspark on the command line inside proper environment\\nAdd to the top of the script\\nimport findspark\\nfindspark.init()',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'PySpark - Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search('Could not establish connection to \"MyServerName\": Got bad result from install script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "06625faa-4215-4df1-8bbb-d5a69034bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag using elastic_search \n",
    "\n",
    "def rag_es(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "22318306-22ae-4004-9d57-adb6cb887401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To enroll in the course, you need to register before the course starts using the provided link. Additionally, make sure to subscribe to the course public Google Calendar (Desktop only) and join the course Telegram channel with announcements. Remember to also register in DataTalks.Club's Slack and join the channel.\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_es('How do I enroll the course')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b5802d-e59a-49d6-8796-b9b089de275f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19e8cb60-6cbc-44e3-846b-c3f8058a03a2",
   "metadata": {},
   "source": [
    "## HW-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4d1bdc91-4ad0-43af-808b-df6ea1efe845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents_hw01 = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents_hw01.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f3a14094-09a0-46a1-8a97-ff533e7da344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_hw01[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9db0c-e608-47ab-9187-c84133fafa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es.indices.create(index = index_name, body = index_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d84582aa-9f89-4550-be72-d8d78e738c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:22<00:00, 41.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# applying the index to the document\n",
    "\n",
    "for doc in tqdm(documents_hw01):\n",
    "    es.index(index = index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "73c1734a-661e-43b7-9c72-bf1c103a1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_hw = \"How do I execute a command in a running docker container?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d75d1384-c963-479a-842e-9f668de29b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the query\n",
    "\n",
    "search_query2 = {\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query_hw,\n",
    "                    \"fields\": [\"question^4\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"machine-learning-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b772a933-7b4f-494c-af49-f943be7d339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_hw = es.search(index= index_name, body = search_query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2a19b492-623b-4fcd-ac48-64a07ea1ed72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 12, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 690, 'relation': 'eq'}, 'max_score': 84.17781, 'hits': [{'_index': 'course-questions', '_id': 'XqFzfpAB2FQzjgIVumZY', '_score': 84.17781, '_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I debug a docker container?', 'course': 'machine-learning-zoomcamp'}}, {'_index': 'course-questions', '_id': 'EqGWfpAB2FQzjgIVwGrl', '_score': 84.17781, '_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I debug a docker container?', 'course': 'machine-learning-zoomcamp'}}, {'_index': 'course-questions', '_id': 'faFzfpAB2FQzjgIVvWZF', '_score': 51.134113, '_source': {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\", 'section': '5. Deploying Machine Learning Models', 'question': 'How do I copy files from my local machine to docker container?', 'course': 'machine-learning-zoomcamp'}}]}})"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "465b3afb-26c5-4248-bbdf-ea0d9460e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_docs_hw = []\n",
    "\n",
    "for hit in response_hw['hits']['hits']:\n",
    "    response_docs_hw.append(hit['_source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc097527-226f-43c9-a51e-2170ea325b9f",
   "metadata": {},
   "source": [
    "response_docs_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e004a7f7-8ee7-47a5-89c3-8d9bf3069797",
   "metadata": {},
   "outputs": [],
   "source": [
    "context =\"\"\n",
    "    \n",
    "for doc in response_docs_hw:\n",
    "    context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "prompt = prompt_template.format(question = query, context = context).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "421051d3-8942-4717-bfd5-b2521b02fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ Database. Do not explicitly use the word CONTEXT in your response. \n",
    "    use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    if the CONTEXT does not contain the answer, output NONE.\n",
    "    \n",
    "    QUESTION : {question}\n",
    "    \n",
    "    CONTEXT : {context}\n",
    "    \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "11c616d6-66bb-4f8d-8cc0-ad30f63acee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_hw = prompt_template.format(question = query_hw, context = context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3eb043d1-ac35-4929-bc6e-b682a21e1333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ Database. Do not explicitly use the word CONTEXT in your response. \\n    use only the facts from the CONTEXT when answering the QUESTION.\\n    if the CONTEXT does not contain the answer, output NONE.\\n    \\n    QUESTION : How do I execute a command in a running docker container?\\n    \\n    CONTEXT : section: 5. Deploying Machine Learning Models\\nquestion: How do I debug a docker container?\\nanswer: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\\n\\nsection: 5. Deploying Machine Learning Models\\nquestion: How do I debug a docker container?\\nanswer: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\\n\\nsection: 5. Deploying Machine Learning Models\\nquestion: How do I copy files from my local machine to docker container?\\nanswer: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\""
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bf3cae6d-6432-4f74-8260-60a2a70b08a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1714"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ad6dedfb-0b08-453a-a15b-28031643dcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To execute a command in a running docker container, you can use the `docker exec` command followed by the container id and the command you want to execute.'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining Both GPT and The Search result\n",
    "answer_hw = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\":\"user\", \"content\":prompt_hw}]\n",
    "\n",
    ")\n",
    "   \n",
    "answer_hw.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b5314bb8-1172-46b2-b90b-e34d5ba37d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_hw.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "77ab4211-e648-4123-9828-498ac6f3e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.5.15 tiktoken-0.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "802b079a-a0bf-485f-93b7-69ee53cc2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8c0bf3c0-af45-462a-ab9c-205fdc48b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "19a17af9-59e1-467b-a83d-f58bb5648bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2675,\n",
       " 2351,\n",
       " 264,\n",
       " 3388,\n",
       " 12917,\n",
       " 18328,\n",
       " 13,\n",
       " 22559,\n",
       " 279,\n",
       " 91022,\n",
       " 3196,\n",
       " 389,\n",
       " 279,\n",
       " 88436,\n",
       " 505,\n",
       " 279,\n",
       " 32072,\n",
       " 10199,\n",
       " 13,\n",
       " 3234,\n",
       " 539,\n",
       " 21650,\n",
       " 1005,\n",
       " 279,\n",
       " 3492,\n",
       " 88436,\n",
       " 304,\n",
       " 701,\n",
       " 2077,\n",
       " 13,\n",
       " 720,\n",
       " 262,\n",
       " 1005,\n",
       " 1193,\n",
       " 279,\n",
       " 13363,\n",
       " 505,\n",
       " 279,\n",
       " 88436,\n",
       " 994,\n",
       " 36864,\n",
       " 279,\n",
       " 91022,\n",
       " 627,\n",
       " 262,\n",
       " 422,\n",
       " 279,\n",
       " 88436,\n",
       " 1587,\n",
       " 539,\n",
       " 6782,\n",
       " 279,\n",
       " 4320,\n",
       " 11,\n",
       " 2612,\n",
       " 43969,\n",
       " 627,\n",
       " 1084,\n",
       " 262,\n",
       " 91022,\n",
       " 551,\n",
       " 2650,\n",
       " 656,\n",
       " 358,\n",
       " 9203,\n",
       " 264,\n",
       " 3290,\n",
       " 304,\n",
       " 264,\n",
       " 4401,\n",
       " 27686,\n",
       " 5593,\n",
       " 5380,\n",
       " 1084,\n",
       " 262,\n",
       " 88436,\n",
       " 551,\n",
       " 3857,\n",
       " 25,\n",
       " 220,\n",
       " 20,\n",
       " 13,\n",
       " 71695,\n",
       " 287,\n",
       " 13257,\n",
       " 21579,\n",
       " 27972,\n",
       " 198,\n",
       " 7998,\n",
       " 25,\n",
       " 2650,\n",
       " 656,\n",
       " 358,\n",
       " 7542,\n",
       " 264,\n",
       " 27686,\n",
       " 5593,\n",
       " 5380,\n",
       " 9399,\n",
       " 25,\n",
       " 24083,\n",
       " 279,\n",
       " 5593,\n",
       " 2217,\n",
       " 304,\n",
       " 21416,\n",
       " 3941,\n",
       " 323,\n",
       " 68971,\n",
       " 279,\n",
       " 4441,\n",
       " 2837,\n",
       " 11,\n",
       " 779,\n",
       " 430,\n",
       " 433,\n",
       " 8638,\n",
       " 264,\n",
       " 28121,\n",
       " 3290,\n",
       " 627,\n",
       " 29748,\n",
       " 1629,\n",
       " 482,\n",
       " 275,\n",
       " 1198,\n",
       " 4177,\n",
       " 2837,\n",
       " 28121,\n",
       " 366,\n",
       " 1843,\n",
       " 397,\n",
       " 2746,\n",
       " 279,\n",
       " 5593,\n",
       " 374,\n",
       " 2736,\n",
       " 4401,\n",
       " 11,\n",
       " 9203,\n",
       " 264,\n",
       " 3290,\n",
       " 304,\n",
       " 279,\n",
       " 3230,\n",
       " 5593,\n",
       " 512,\n",
       " 29748,\n",
       " 4831,\n",
       " 320,\n",
       " 3990,\n",
       " 279,\n",
       " 5593,\n",
       " 13193,\n",
       " 340,\n",
       " 29748,\n",
       " 3969,\n",
       " 482,\n",
       " 275,\n",
       " 366,\n",
       " 3670,\n",
       " 13193,\n",
       " 29,\n",
       " 28121,\n",
       " 198,\n",
       " 3269,\n",
       " 8362,\n",
       " 437,\n",
       " 386,\n",
       " 51015,\n",
       " 696,\n",
       " 2879,\n",
       " 25,\n",
       " 220,\n",
       " 20,\n",
       " 13,\n",
       " 71695,\n",
       " 287,\n",
       " 13257,\n",
       " 21579,\n",
       " 27972,\n",
       " 198,\n",
       " 7998,\n",
       " 25,\n",
       " 2650,\n",
       " 656,\n",
       " 358,\n",
       " 7542,\n",
       " 264,\n",
       " 27686,\n",
       " 5593,\n",
       " 5380,\n",
       " 9399,\n",
       " 25,\n",
       " 24083,\n",
       " 279,\n",
       " 5593,\n",
       " 2217,\n",
       " 304,\n",
       " 21416,\n",
       " 3941,\n",
       " 323,\n",
       " 68971,\n",
       " 279,\n",
       " 4441,\n",
       " 2837,\n",
       " 11,\n",
       " 779,\n",
       " 430,\n",
       " 433,\n",
       " 8638,\n",
       " 264,\n",
       " 28121,\n",
       " 3290,\n",
       " 627,\n",
       " 29748,\n",
       " 1629,\n",
       " 482,\n",
       " 275,\n",
       " 1198,\n",
       " 4177,\n",
       " 2837,\n",
       " 28121,\n",
       " 366,\n",
       " 1843,\n",
       " 397,\n",
       " 2746,\n",
       " 279,\n",
       " 5593,\n",
       " 374,\n",
       " 2736,\n",
       " 4401,\n",
       " 11,\n",
       " 9203,\n",
       " 264,\n",
       " 3290,\n",
       " 304,\n",
       " 279,\n",
       " 3230,\n",
       " 5593,\n",
       " 512,\n",
       " 29748,\n",
       " 4831,\n",
       " 320,\n",
       " 3990,\n",
       " 279,\n",
       " 5593,\n",
       " 13193,\n",
       " 340,\n",
       " 29748,\n",
       " 3969,\n",
       " 482,\n",
       " 275,\n",
       " 366,\n",
       " 3670,\n",
       " 13193,\n",
       " 29,\n",
       " 28121,\n",
       " 198,\n",
       " 3269,\n",
       " 8362,\n",
       " 437,\n",
       " 386,\n",
       " 51015,\n",
       " 696,\n",
       " 2879,\n",
       " 25,\n",
       " 220,\n",
       " 20,\n",
       " 13,\n",
       " 71695,\n",
       " 287,\n",
       " 13257,\n",
       " 21579,\n",
       " 27972,\n",
       " 198,\n",
       " 7998,\n",
       " 25,\n",
       " 2650,\n",
       " 656,\n",
       " 358,\n",
       " 3048,\n",
       " 3626,\n",
       " 505,\n",
       " 856,\n",
       " 2254,\n",
       " 5780,\n",
       " 311,\n",
       " 27686,\n",
       " 5593,\n",
       " 5380,\n",
       " 9399,\n",
       " 25,\n",
       " 1472,\n",
       " 649,\n",
       " 3048,\n",
       " 3626,\n",
       " 505,\n",
       " 701,\n",
       " 2254,\n",
       " 5780,\n",
       " 1139,\n",
       " 264,\n",
       " 41649,\n",
       " 5593,\n",
       " 1701,\n",
       " 279,\n",
       " 27686,\n",
       " 12773,\n",
       " 3290,\n",
       " 13,\n",
       " 5810,\n",
       " 596,\n",
       " 1268,\n",
       " 311,\n",
       " 656,\n",
       " 433,\n",
       " 512,\n",
       " 1271,\n",
       " 3048,\n",
       " 264,\n",
       " 1052,\n",
       " 477,\n",
       " 6352,\n",
       " 505,\n",
       " 701,\n",
       " 2254,\n",
       " 5780,\n",
       " 1139,\n",
       " 264,\n",
       " 4401,\n",
       " 41649,\n",
       " 5593,\n",
       " 11,\n",
       " 499,\n",
       " 649,\n",
       " 1005,\n",
       " 279,\n",
       " 1595,\n",
       " 29748,\n",
       " 12773,\n",
       " 3290,\n",
       " 29687,\n",
       " 578,\n",
       " 6913,\n",
       " 20047,\n",
       " 374,\n",
       " 439,\n",
       " 11263,\n",
       " 512,\n",
       " 29748,\n",
       " 12773,\n",
       " 611,\n",
       " 2398,\n",
       " 33529,\n",
       " 23066,\n",
       " 24849,\n",
       " 8908,\n",
       " 15191,\n",
       " 5593,\n",
       " 851,\n",
       " 14712,\n",
       " 2398,\n",
       " 18480,\n",
       " 84997,\n",
       " 198,\n",
       " 39,\n",
       " 81,\n",
       " 411,\n",
       " 1609,\n",
       " 41240,\n",
       " 12605,\n",
       " 5676]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(prompt_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e998bf23-9039-44e3-83a2-464dd8f47edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(prompt_hw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d050b928-c609-422b-ac1c-a9240df18ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'You'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode_single_token_bytes(2675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ee002-baaa-41a5-9257-9da658a67c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
